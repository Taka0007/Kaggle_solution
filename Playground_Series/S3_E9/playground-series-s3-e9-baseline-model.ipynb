{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#import\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import cohen_kappa_score\nimport xgboost as xgb \nfrom xgboost import XGBClassifier\nimport lightgbm as lgm\nimport warnings\nwarnings.simplefilter('ignore')\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-05T06:03:38.507983Z","iopub.execute_input":"2023-03-05T06:03:38.508385Z","iopub.status.idle":"2023-03-05T06:03:38.516456Z","shell.execute_reply.started":"2023-03-05T06:03:38.508352Z","shell.execute_reply":"2023-03-05T06:03:38.515021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# データをロード\n# load data\npath  = '/kaggle/input/playground-series-s3e9/'\npretrain = pd.read_csv(path+'train.csv').drop(['id','FlyAshComponent'],axis=1)\npretest  = pd.read_csv(path+'test.csv').drop(['id','FlyAshComponent'],axis=1)\nsub   = pd.read_csv(path +'sample_submission.csv')\n\n# 目的変数\n# Objective variable\ntarget = 'Strength'\n\n\n# 目的変数の列を除いたデータ\n# Data excluding columns for the objective variable\ntrain = pretrain.drop(target,axis=1)\n\n\n# 目的変数列のデータ\n# Data for the objective variable column\ntrain_tgt  = pretrain[target]\n\n\n# split列の作成\n# Creating a split column\npretrain['split']= 'train'\npretest['split']= 'test'\ndata = pd.concat([pretrain,pretest]).reset_index(drop=True)\n\n\n# 特徴量\n# feature value\nfeatures = [c for c in train.columns if c not in ['id',target]]","metadata":{"execution":{"iopub.status.busy":"2023-03-05T06:03:38.519209Z","iopub.execute_input":"2023-03-05T06:03:38.520044Z","iopub.status.idle":"2023-03-05T06:03:38.558710Z","shell.execute_reply.started":"2023-03-05T06:03:38.519975Z","shell.execute_reply":"2023-03-05T06:03:38.557505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trainの欠損値情報の把握＆先頭の情報の出力\n# Capturing missing value information of train \n# outputting information at the beginning of the train\npretrain.info()\npretrain.head(3)\n\n\n# 特徴量の分布を図示\n# Graphical representation of feature distribution\nfig, axs = plt.subplots(7,1, figsize=(14,12))\nfor f, ax in zip(features,axs.ravel()):\n    sns.histplot(data, x=f, hue='split', ax=ax)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-05T06:03:38.560700Z","iopub.execute_input":"2023-03-05T06:03:38.561179Z","iopub.status.idle":"2023-03-05T06:03:41.394184Z","shell.execute_reply.started":"2023-03-05T06:03:38.561128Z","shell.execute_reply":"2023-03-05T06:03:41.392863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 予測に不要なのでsplitの列を削除\n# Remove split columns as they are not needed for forecasting\ntest = pretest.drop('split',axis=1)\n\n\n# 訓練・テストデータに分割\n# Split into training and test data\nX_train, X_test, y_train, y_test = train_test_split(train, train_tgt, test_size=0.2, shuffle=True)\n\n\n# xgboostモデルの仮作成\n# Tentative creation of xgboost model\nmodel = xgb.XGBRegressor()\n\n# ここをいじるとハイパーパラメーターを調整できます。\n# You can adjust the hyper parameters by tinkering here.\ndepth     = [2]\nestimator = [18]\n\n\n# ハイパーパラメータ探索\n# Hyperparameter Search\nmodel_cv = GridSearchCV(model, {'max_depth': depth, 'n_estimators':estimator},verbose=3)\nmodel_cv.fit(X_train, y_train)\nprint(model_cv.best_params_, model_cv.best_score_)\n\n\n# 改めて最適パラメータで学習\n# Learning again with optimal parameters\nmodel = xgb.XGBRegressor(**model_cv.best_params_)\nmodel.fit(X_train, y_train)\n\n\n\n# 学習モデルの評価・出力（RMSE）\n# Evaluate and output the learning model (RMSE)\ny_pred_train = model.predict(X_train)\ny_pred_test = model.predict(X_test)\nprint('RMSE(train data):',round(np.sqrt(mean_squared_error(y_train, y_pred_train)),3))\nprint('RMSE(test data):',round(np.sqrt(mean_squared_error(y_test, y_pred_test)),3))\n\n\n# ミスしていないか確認するための出力\n# Output to check for mistakes\nprint(y_pred_train)\nprint(y_pred_test)\n\n\n#テストデータの予測,提出\n#Prediction of test data, submission\npred = model.predict(test)\nsub[target] = pred\nsub.to_csv('submission.csv', index=False)\nprint(sub)\n\n# ヒストグラム\n# histogram\ndata = np.array(pred)\nfig = plt.figure()\nax = fig.add_subplot(1, 1, 1)\nax.hist(data, bins='auto', histtype='barstacked', ec='black')\nplt.show()\n\n# 重要度の図示\n# Illustration of importance\nimportances = pd.Series(model.feature_importances_, index =features)\nimportances = importances.sort_values()\nimportances.plot(kind = \"barh\")\nplt.title(\"imporance in the xgboost Model\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-05T06:03:41.396288Z","iopub.execute_input":"2023-03-05T06:03:41.396754Z","iopub.status.idle":"2023-03-05T06:03:42.392763Z","shell.execute_reply.started":"2023-03-05T06:03:41.396711Z","shell.execute_reply":"2023-03-05T06:03:42.391418Z"},"trusted":true},"execution_count":null,"outputs":[]}]}